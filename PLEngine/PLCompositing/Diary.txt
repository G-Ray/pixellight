>> 21.04.2011
[CO]
- Moved the content from "SRPDebugHierarchiesFixedFunctions" into "SRPDebugHierarchies" because a special fixed functions or shader implementation is no longer
  required (the internally used draw helpers deal for us with this issue)
- Moved the content from "SRPDebugContainerScissorRectanglesFixedFunctions" into "SRPDebugContainerScissorRectangles" because a special fixed functions or shader
  implementation is no longer required (the internally used draw helpers deal for us with this issue)



>> 17.04.2011
[CO]
- Removed usage of fixed functions stuff within "PostProcessor"



>> 11.04.2011
[CO]
- Removed the usage of "isnan" within the GLSL shaders so that I have a change to use lower shader versions to enhance compatibility, especially with out-of-date
  graphics drivers. It looks like that according to the IEEE standard NaN != NaN so that this test can also be done without the shader language build in "isnan".
  (had a look into the NAN-issue, again... but right now, I don't have many hours available...)
- Continued migration to lower GLSL versions for enhanced compatibility



>> 10.04.2011
[CO]
- There were some OpenGL GLSL issues when using GLSL 1.30... there are still old GPU drivers out there, and sometimes (e.g. some Notebooks!) it's not
  that trivial to update the GPU driver... so I now try to use the lowest possible GLSL version... started to update the GLSL shader source codes...



>> 08.04.2011
[CO]
- Added "SRPDeferredVolumetricFog" which is a special version of "SRPVolumetricFog" for deferred rendering -> "SRPDeferredVolumetricFog" comes with
  better performance because it's entirely image space based and not rendering geometries over again.
- "SRPLightingMaterial" & "SRPDirectionalLightingShadersMaterial" & "SRPDeferredGBufferMaterial" are now using the new 
  "PLRenderer::Material::EventParameterChanged"-event to make the cached material "dirty"
- "SRPLighting" & "SRPDirectionalLightingShaders" & "SRPDeferredGBuffer" are now using a material cache to reduce required CPU time
  (the material is interpreted only once, and not during every material switch)



>> 29.03.2011
[CO]
- Added "SRPDeferredSPAAO" which is an implementation of the article "A Simple and Practical Approach to SSAO".
  (http://www.gamedev.net/page/reference/index.html/_/reference/programming/140/lighting-and-shading/a-simple-and-practical-approach-to-ssao-r2753)
  The result looks ok - and the performance is better... therefore this is now the active default SSAO implementation.



>> 12.03.2011
[CO]
- Added SRPDirectionalLightingShadersMaterial for the SRPDirectionalLightingShaders material interpretation
- Added SRPLightingMaterial for the SRPLighting material interpretation
-> Ok, I think a material interpretation class is really a good idea, it improves the code readability a lot. :D
   Later, this approach may also make it easier to add e.g. Uniform Buffer Object (ARB_Uniform_Buffer_Object -
   http://www.opengl.org/registry/specs/ARB/uniform_buffer_object.txt) support for faster material switching, but
   right now, I'am happy when the material caching works.



>> 11.03.2011
[CO]
- SRPDeferredGBuffer refactoring: The material stuff known to this compositing step is now hold within an own SRPDeferredGBufferMaterial class. This
  enhances the clarity of the SRPDeferredGBuffer implementation and allows further performance improvements... if this experiment works, the other
  compositing steps will be refactored in the same way...



>> 08.03.2011
[CO]
- After installing "AMD Catalyst 11.2", I noticed that the Dungeon demo looked different when using Cg shaders, while GLSL shaders were still ok.
  On a NVIDIA system, I noticed a similar issue, but with correctly working Cg shaders while the GLSL shaders produced the error. After looking into
  the issue, I narrowed it down to the HDRBloom & SRPEndHDR classes - to the vertex texture fetch (VTF) used to read out the current automatically calculated
  luminance of the image, to be exactly. When fetching the texel within the fragment shader everything is fine, but as soon as I use VTF to reduce the total
  number of required texture accesses within the fragment shader, the resulting image is just wrong. It looks like the read luminance has always the same value
  (but no compiler errors or something like that).
  Right now, I have no glue whether this is a driver or Cg issue, or whether I do something wrong - which worked with previous GPU driver versions but not on
  new ones. So, I just added a flag to SRPEndHDR controlling whether or not vertex texture fetch should be used, by default, it's disabled to avoid this issue.



/*********************************************************\
 *  The entries below are in german only
\*********************************************************/



>> 26.11.2010
[CO]
- Bisher lagen bereits alle Fixed-Functions basierenden Compositing Dinge in einem "FixedFunctions"-Unterordner. Bei Shader basierenden Dingen
  war ich mir damals als ich mit PLCompositing began noch unsicher ob man das auch in einen "Shaders"-Unterordner packen sollte, da heute eigentlich
  alles Shader basierend ist. Mittlerweile habe ich allerdings zwei gute Gründe dafür auch einen "Shaders"-Unterordner zu haben:
  1. Neben "Fixed Functions Rendering" und "Shaders Rendering" gibts da draußen in der Welt auch immer noch "Software Rendering", das mal aus Spaß
     an der Freud umgesetzt wird, oder weil eine bestimmte Hardware keinerlei GPU bzw. Render-Support hat (heute wohl eher selten, selbst bei
     Mobilen Geräten :)
     In die sparte "Software Rendering" fällt meist auch soetwas wie "Raytracting/Raycasting", was mittlerweile stellenweise bereits aber auch
     mit Hardware Support möglich ist. Desweiteren besteht heute auch die Möglichkeit z.B. über OpenCL Bildgeneration/Bildbearbeitung zu betreiben -
     ich kann es mir gut vorstellen das wir irgendann auch mal einen "OpenCL"-Unterordner haben... :D
  2. Sinn des PLCompositing Projektes besteht darin, bei Zeiten alles was mit konkreten Rendern zu tun hat in diesem Projekt zu halten anstatt das
     auch noch in PLScene mit reingestopft zu haben. PLScene ist soweit unabhängig davon, wie dann z.B. eine Szene am Ende konkret auf den Bildschirm
     gebracht wird - falls überhaupt. Mittlerweile bin ich wirklich froh mich damals für ein neues PLCompositing Projekt entschieden zu haben -
     denn hier liegt bereits einiges an Funktionalität drinnen, und es ist abzusehen das hier zusammen mit der Hardware Entwicklung öfters Änderungen
     und Erweiterungen stattfinden werden als z.B. im PLScene Projekt.
- Alles was bisher in "Compositing/General/" & "Compositing/Debug/" & "Compositing/PostProcessing" lag in das Grundverzeichnis von PLCompositing verschoben
- "SNMPostProcess" & "SNMPostProcessDepthOfField" & "SNMPostProcessGlow" von PLScene nach PLCompositing verschoben
- "FullscreenQuad" von PLScene nach PLCompositing verschoben. Diese kleine Helferlein-Klasse hätte man auch genauso gut nach PLRenderer verschieben können,
  allerdings will ich in PLRenderer, wenn es sich vermeiden lässt, nicht noch mehr Zeug packen, vorallem wenn etwas bisher eigentlich nur in einem einzigen
  Projekt verwendet wird.
- "SRPBegin" setzt nun zuallererst die Render-States auf bekannte Werte, das war früher direkt in "PLScene::SceneRenderer::DrawScene()" drinnen
- Das aktuelle Post Processing System "SRPPostProcessing" ans Compositing-System angestöpselt, somit kann man auch beim Deferred Renderer Post Processing
  nutzen
- SRPLightEffects/SRPLightEffectsFixedFunctions: "PrepareStep"-Flag hinzugefügt, ähnlich wie beim Deferred Rendering arbeiten hier mehrere Szene
  Renderer Schritt Instanzen "gemeinsam", müssen also voneinander wissen. In diesem Fall muss die erste SRPLightEffects-Instanz über Occlusion Query
  die Sichtbarkeit feststellen, während die zweite SRPLightEffects-Instanz die ermittelten Informationen der ersten SRPLightEffects-Instanz zum
  zeichnen verwendet. Die aktuelle Lösung ist sicherlich noch nicht perfekt, aber sicherlich deutlich besser als die alte die darin bestand,
  einfach was in "PLScene::SceneRenderer::DrawScene()" fest einzubauen.



>> 12.11.2010
[CO]
- Eigenes Tagebuch für das PLCompositing Projekt angelegt da dieses Projekt mittlerweile einen Umfang erreicht hat wo dies gerechtfertigt ist. Das
  PLCompositing Projekt ist noch relativ jung und bisher wurde das PLScene Tagebuch auch für PLComposing verwendet da die entsprechenden Klassen
  ursprünglich in PLScene lagen (wobei PLScene wiederum früher direkt in PLEngine lag *g*).
- Endlich mit dem längst überfälligen Refactoring des Shadow Mappings begonnen. Verschob als ersten Schritt die aktuelle Shadow Mapping implementation
  von PLScene nach PLCompositing da diese hochspezielle Render-Technik nix im allgemeinen, soweit möglich Render unabhängigen, PLScene Projekt zu
  suchen hat (das PLScene Projekt ist nebenbei ohnehin enorm umfangreich, da muss hier nicht auch noch Shadow Mapping mit reingestopft sein :).
- Bisher lag eine "ShadowMapManager"-Instanz direkt in "PLScene::SceneContext" damit die einzelnden Scene Renderer Pass Implementation irgendwie
  darauf zugreifen konnten. Das stammte noch aus den Urzeiten der ersten Shadow-Mapping Experimente und war noch nie wirklich prall. Damit das
  ganze "von Außen" besser Konfigurierbar wird, ist "ShadowMapManager" nun eine Scene Renderer Pass Implementation - auch wenn das hier minimal
  aus der Reihe tanzt. Zwar wird hier natürlich ebenfalls die Szene "in die Shadow Map" gezeichnet, dies passiert allerdings nicht in einer im
  Scene Renderer über verschiedene Schritte festgelegten Reihenfolge, sondern "on demand" wenn ein Licht gezeichnet wird das Shadow Mapping nutzt.
  Scene Renderer Pass Implementation welche Shadow Mapping nutzen, suchen also nach einer "ShadowMapManager" Instanz innerhalb des Scene Renderers -
  das ist in etwa damit vergleichbar das Deferred Scene Renderer Pass Implementation nach "SRPDeferredGBuffer" suchen um an die Instanz des GBuffers
  zu kommen (wobei der GBuffer hier allerdings in der im Scene Renderer festgelegten Reihenfolge zum füllen aufgerufen wird). Ich weis nicht ob das
  bereits *optimal* ist, habe aber im Augenblick nicht die Weitsicht wie das gesamte PLCompositing System irgendwann später "final" aussehen könnte.
  Es ist auf jedenfall so nun deutlich besser als eine Shadow Mapping Instanz direkt in "PLScene::SceneContext", und man kann endlich über die Scene
  Renderer Schnittstelle auch generelle Shadow Mapping Einstellungen ändern oder komplett andere Shadow Mapping Implentationen nutzen und es ist nun
  endlich alles zusammen was zusammen gehört anstatt über mehrere Projekte verteilt zu sein! "ShadowMapManager" in "SRPShadowMapping" umbenannt.
- SRPShadowMapping ist kein "ElementManager" mehr da "ShadowMap" als eigenständige Klasse bisher nie nötig war
- Der in SRPShadowMapping verwendete Shadow Mapping Algorithmus liegt nun in einer seperaten "ShadowMapping"-Klasse von der es verschiedenste
  Implementationen geben kann. Heutzutage existieren zig verschiedene Shadow Mapping Algorithmen, die für unterschiedliche Einsatzgebiete unterschiedlich
  gute Qualität liefern. Generell scheinen sich die Algorithmen in zwei Kategorien einteilen zu lassen, die einen Algorithmen nutzen nur eine einzige
  Shadow Map während andere (z.B. Cascaded Shadow Mapping (CSM)) mehrere gestaffelte Shadow Maps nutzen um eine bessere Qualität zu erreichen - da die
  letztere Variante etwas aufwändiger ist, berücksichtige ich erstmal nur für erste Kategorie von Algorithmen um nicht den Überblick zu verlieren.
  Bei den Shadow Mapping Algorithmen mit nur einer Shadow Map, scheint nach außen hin gesehen nur die Light View/Projection Matrize etwas anderst berechnet
  zu werden um die Fehler besser zu verteilen... beim nutzen der Shadow Map während der Beleuchtung scheints dann keinen unterschied mehr zugeben... ein Grund
  mehr *erstmal* nur diese Kategorie zu berücksichtigen.
- Bisher verwendeten wir als Shadow Mapping Algorithmus "Uniform Shadow Mapping", die traditionelle Variante welche allerdings auch die schlechtesten Ergebnisse
  liefert. Dieser "Algorithmus" liegt nun in der "ShadowMappingUSM"-Implementation von "ShadowMapping".
- "ShadowMappingUSM::CalculateLightMatrices()": Für Spot-Lights wird nun eine eigene Shadow Light View Matrize mit festen Up-Vektor berechnet anstatt die
  vorhandene View Matrize des Spot Lights zu nutzen... dadurch "rotieren" nun die Shadow Mapping Artefakte nicht mehr mit wenn ein Licht um z.B. dauerhaft um
  die z-Achse gedreht wird. Dies macht die Schatten etwas "ruhiger". :D
